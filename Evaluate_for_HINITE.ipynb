{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37fb4644",
   "metadata": {},
   "source": [
    "Import necessary frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33e6f1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 15:50:02.932187: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "import multiprocessing as mp\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(16,10)}, font_scale=1.3)\n",
    "import utils\n",
    "import HINITE\n",
    "import ourlayers\n",
    "import evaluation\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70d895e",
   "metadata": {},
   "source": [
    "Load the Youtube dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1689e0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.load_data(\"Youtube\")\n",
    "train_idx,val_idx,test_idx = utils.split_train_val_test(data[0][0],0.7,0.15,0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f699de11",
   "metadata": {},
   "source": [
    "Set parameters for the HINITE's architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3a6a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs,activation = utils.config_pare_HINITE(iterations=2000,lr_rate=0.001,lr_weigh_decay=0.001,flag_early_stop=True,use_batch=512,\n",
    "    rep_alpha=[0.05,0.1,0.5,1.0,1.5],flag_norm_gnn=False,flag_norm_rep=False,out_dropout=0.2,GNN_dropout=0.2,rep_dropout=0.2,inp_dropout=0.0,\n",
    "    rep_hidden_layer=3,rep_hidden_shape=[128,64,64],GNN_hidden_layer=3,GNN_hidden_shape=[64,64,32], divide = True,\n",
    "    head_num_att=1,out_T_layer=3,out_C_layer=3,out_hidden_shape= [128,64,32],activation = tf.nn.relu,GNN_alpha = [0.0],hete_att_size = [128,128,64]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf128f9a",
   "metadata": {},
   "source": [
    "Choose the model (with different hyperparameters) by checking PEHE in the validation set, and save the result in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6d6d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    temp = [0.01,0.1,0.5,1.0, 1.5]\n",
    "    cur_all_input, yf,mu1,mu0,adjs= utils.data_preparation('Youtube',i,data)\n",
    "    true_ite = mu1 - mu0\n",
    "    val_true_ite = true_ite[val_idx]\n",
    "    print(\"val true ite\",val_true_ite)\n",
    "    val_true_ate = np.mean(true_ite[val_idx])\n",
    "    test_true_ite = true_ite[test_idx]\n",
    "    print(\"test ite\",val_true_ite)\n",
    "    test_true_ate = np.mean(true_ite[test_idx])\n",
    "    best_pehe = 1e10\n",
    "    best_err_ate = 1e10\n",
    "    best_model = None\n",
    " \n",
    "    for j in range(len(temp)):\n",
    "        #Model_new_ASGLITE.ASGLITEModel_gcn_k3212_eps0.0__concat_split_9cross_alpha0.1rebuilding\n",
    "        #test_index, cur_all_input, cur_all_y, cur_all_e = utils.data_preparation(\"job\",i,all_data)\n",
    "        cur_path = \"./save_Models_HINITE/Model_Youtube1.01.0HINITE.HINITEModel_divide_True_split_\" + str(i) +\"rep_alpha\" + str(temp[j]) \n",
    "        cur_name = \"model\"\n",
    "        cur_model = utils.load_mymodel(cur_path, cur_name,HINITE.HINITEModel,configs[0],tf.nn.relu,adjs)\n",
    "        pehe_val,err_ate_val = evaluation.evalate(Model = cur_model,inputtensor=tf.cast(cur_all_input,tf.float32),test_idx=val_idx,true_ate = tf.cast(val_true_ate,tf.float32), true_y = yf,true_ite = val_true_ite,RCT_flags = None)\n",
    "\n",
    "        if err_ate_val < best_err_ate:\n",
    "            best_err_ate  = err_ate_val\n",
    "            print(\"best_err_ate\",err_ate_val)\n",
    "            #save_mymodel('./Best_Model_new_spilt'+str(i),cur_model)\n",
    "            #save_mymodel(best_save_path,best_save_name,cur_model)\n",
    "            #np.save(\"./results/best_blog_re_buildGATCFRconfig_split_\"+str(i),config)\n",
    "            best_model = cur_model\n",
    "        elif err_ate_val == best_err_ate and  pehe_val < best_pehe:\n",
    "            best_pehe = pehe_val\n",
    "            #save_mymodel('./Best_Model_new_spilt'+str(i),cur_model)\n",
    "            #save_mymodel(best_save_path,best_save_name,cur_model)\n",
    "            #np.save(\"./results/best_blog_re_buildGATCFRconfig_split_\"+str(i),config)\n",
    "            best_model = cur_model\n",
    "\n",
    "\n",
    "        cur_test_results = []\n",
    "        pehe_test,err_ate_test = evaluation.evalate(Model = best_model,inputtensor=tf.cast(cur_all_input,tf.float32),test_idx=test_idx,true_ate = tf.cast(test_true_ate,tf.float32), true_y = yf,true_ite = test_true_ite,RCT_flags = None)\n",
    "        cur_test_results_name = './results/test_results_Youtube_repalpha' + str(HINITE.HINITEModel)[8:-2]  +  \"split_\" + str(i) \n",
    "        cur_test_results.append(pehe_test)\n",
    "        cur_test_results.append(err_ate_test)\n",
    "        print(\"test pehe\",pehe_test)\n",
    "\n",
    "        utils.save_results(cur_test_results,cur_test_results_name )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e00b06",
   "metadata": {},
   "source": [
    "Load result that you saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7955509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha 0.01,0.1,0.5,1.0,1.5 Youtube\n",
    "ate_all = []\n",
    "pehe_all = []\n",
    "for i in range(10):\n",
    "    cur_test_results_name = './results/test_results_Youtube_repalpha' + str(HINITE.HINITEModel)[8:-2]  +  \"split_\" + str(i)  +\".npy\"\n",
    "    cur_result = np.load(cur_test_results_name ,allow_pickle=True)\n",
    "    cur_ate =  cur_result[1]\n",
    "    cur_pehe =  cur_result[0]\n",
    "    ate_all.append(np.float(cur_ate))\n",
    "    pehe_all.append(np.float(cur_pehe))\n",
    "print(ate_all)\n",
    "pehe_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d141dc",
   "metadata": {},
   "source": [
    "Evaluate results on the Youtube dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha 0.01,0.1,0.5,1.0,1.5] Youtube\n",
    "print(np.mean(pehe_all),np.std(pehe_all))\n",
    "print(np.mean(ate_all),np.std(ate_all))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
